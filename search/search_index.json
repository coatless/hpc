{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to HPC \u00b6 The goal of High Performance Computing on a Cluster with R is to inform and distribute various recipes and techniques for performing computational-intensive work on remote computing resources. Thanks! \u00b6 This work made use of the Illinois Campus Cluster, a computing resource that is operated by the Illinois Campus Cluster Program (ICCP) in conjunction with the National Center for Supercomputing Applications (NCSA) and which is supported by funds from the University of Illinois at Urbana-Champaign .","title":"Home"},{"location":"#welcome-to-hpc","text":"The goal of High Performance Computing on a Cluster with R is to inform and distribute various recipes and techniques for performing computational-intensive work on remote computing resources.","title":"Welcome to HPC"},{"location":"#thanks","text":"This work made use of the Illinois Campus Cluster, a computing resource that is operated by the Illinois Campus Cluster Program (ICCP) in conjunction with the National Center for Supercomputing Applications (NCSA) and which is supported by funds from the University of Illinois at Urbana-Champaign .","title":"Thanks!"},{"location":"cluster-computing/","text":"Cluster Computing \u00b6 What is Cluster Computing? \u00b6 Definition: Cluster A cluster is a set of computers that are connected together and share resources as if they were one gigantic computer. How Does Cluster Computing WorK? \u00b6 Definition: Parallel Processing Parallel Processing is the act of carrying out multiple tasks simultaneously to solve a problem. This is accomplished by dividing the problem into independent subparts, which are then solved concurrently. Definition: Jobs Jobs denote the independent subparts. Why use Cluster Computing? \u00b6 Pros Speeds up simulations by allowing iterations to be run simultaneously. Provides more resources for computations. e.g. CPU Cores, RAM, Hard Drive Space, and Graphics Cards (GPUs). Nightly snapshots/backups of files. Extends the lifespan of your computer. Cons Simulations are not instantly run. Need to \"queue\" for resources. Higher barrier of entry due to knowledge requirements. Poorly handles opening and closing data sets. Adding or updating software is complex.","title":"Overview of Cluster Computing"},{"location":"cluster-computing/#cluster-computing","text":"","title":"Cluster Computing"},{"location":"cluster-computing/#what-is-cluster-computing","text":"Definition: Cluster A cluster is a set of computers that are connected together and share resources as if they were one gigantic computer.","title":"What is Cluster Computing?"},{"location":"cluster-computing/#how-does-cluster-computing-work","text":"Definition: Parallel Processing Parallel Processing is the act of carrying out multiple tasks simultaneously to solve a problem. This is accomplished by dividing the problem into independent subparts, which are then solved concurrently. Definition: Jobs Jobs denote the independent subparts.","title":"How Does Cluster Computing WorK?"},{"location":"cluster-computing/#why-use-cluster-computing","text":"Pros Speeds up simulations by allowing iterations to be run simultaneously. Provides more resources for computations. e.g. CPU Cores, RAM, Hard Drive Space, and Graphics Cards (GPUs). Nightly snapshots/backups of files. Extends the lifespan of your computer. Cons Simulations are not instantly run. Need to \"queue\" for resources. Higher barrier of entry due to knowledge requirements. Poorly handles opening and closing data sets. Adding or updating software is complex.","title":"Why use Cluster Computing?"},{"location":"cluster-setup/","text":"Cluster Setup \u00b6 Within this chapter, we will cover establishing a workspace on the Campus Cluster. Workspace setup usually requires about 5 different steps. Ensure the cluster can easily be accessed from a local computer. Enable command shortcuts through aliases. Setup a GitHub access token for pulling software in from private repositories (skip if not needed). Create a space on a project drive for where R packages should be installed. Install R packages! Secure Shell (SSH) Setup \u00b6 For accessing a cluster from command line, Secure Shell (SSH) is preferred. Access to the cluster requires typing out each time: ssh netid@cc-login.campuscluster.illinois.edu # password Connecting in this manner is tedious since it involves repetitively typing out login credentials. There are two tricks that void the necessity to do so. Effectively, we have: Passwordless login Public/Private SSH Keys Alias connection names SSH Config Thus, instead of entering a password, the local computer can submit a private key to be verified by a server. Not only is this more secure, but it avoids the hassle of remembering the password and typing it out while observers watch. Secondly, the connection alias will allow for typing: ssh icc Not bad eh? Generating an SSH Key \u00b6 On your local computer, open up Terminal and type: ## Run: ssh-keygen -t rsa -C \"netid@illinois.edu\" ## Respond to: # Enter file in which to save the key (/home/demo/.ssh/id_rsa): # [Press enter] # Enter passphrase (empty for no passphrase): # Write short password Copy SSH Key to Server \u00b6 Next, let's copy the generated key from your local computer onto the cluster. ## Run: ssh-copy-id netid@cc-login.campuscluster.illinois.edu On macOS, prior to using ssh-copy-id , the command will need to be installed. Homebrew provides a formula that will setup the command. Install using: # Install homebrew /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh ) \" # Install the required command binary brew install ssh-copy-id SSH Config File \u00b6 Inside of ~/.ssh/config , add the following host configuration. Make sure to replace <netid> value with your personal netid. Host icc HostName cc-login.campuscluster.illinois.edu User netid Note: This assumes a default location is used for the SSH key. If there is a custom SSH key location add IdentityFile ~/.ssh/sshkeyname.key after the User line. Bash Aliases \u00b6 Bash has the ability to create command aliases through alias . The primary use is to take long commands and create short-cuts to avoid typing them. Alternatively, this allows one to also rename commonly used commands. For example, one could modify the ls command to always list each file and show all hidden files with: alias ls = 'ls -la' ` . We suggest creating a ~/.bash_aliases on the cluster and filling it with: # Learn about own job progress alias jobs_info = 'sacct -u $USER' alias jobs_user = 'squeue -u $USER' alias jobs_active = 'squeue -u $USER --states=RUNNING' alias jobs_waiting = 'squeue -u $USER --states=PENDING' alias jobs_n = 'squeue -u $USER --states=RUNNING | wc -l' # Learn about cluster work alias jobs_stat = 'squeue -o \"%8i %12j %4t %10u %20q %20a %10g %20P %10Q %5D %11l %11L %R\" -p \"stat\"' alias node_config = 'sinfo -o \"%20P %5D %14F %8z %10m %10d %11l %16f %N\"' # Quick action job manipulations alias jobs_hold = 'scontrol hold' alias jobs_release = 'scontrol release' alias jobs_kill_all = 'scancel -u $USER' alias jobs_kill = 'scancel' # Run an interactive job alias si = 'srun --cpus-per-task=5 --pty bash' You may download this directly onto the cluster using: wget https://raw.githubusercontent.com/coatless/hpc/master/docs/config/.bash_aliases To ensure bash aliases are available, we need to add the file to ~/.bashrc : # .bashrc # Source global definitions if [ -f /etc/bashrc ] ; then . /etc/bashrc fi # Source list of alias commands if [ -f ~/.bash_aliases ] ; then . ~/.bash_aliases fi # Auto-load a set of modules if [ -f ~/.init_modules ] ; then . ~/.init_modules fi Note: the load modules component is shown You may download this directly onto the cluster using: rm -rf ~/.bashrc wget https://raw.githubusercontent.com/coatless/hpc/master/docs/config/.bashrc Optional: GitHub Personal Access Token (PAT) \u00b6 We briefly summarize the process for getting and registering a GitHub Personal Access Token in R . The token may be created at: https://github.com/settings/tokens From there, we can add it to the R session with: touch ~/.Renviron cat << EOF >> ~/.Renviron GITHUB_TOKEN=\"your_github_token_here\" GITHUB_PAT=\"your_github_token_here\" EOF Alternatively, within R , the token can be added by typing: file.edit ( \"~/.Renviron\" ) Then, writing in the configuration file: GITHUB_TOKEN = \"your_github_token_here\" GITHUB_PAT = \"your_github_token_here\" Default R Package Storage Location \u00b6 R 's default library directory where packages are installed into is found within the user's home directory at: # location for R 3.6.z /home/ $USER /R/x86_64-pc-linux-gnu-library/3.6 # location for R 4.0.z /home/ $USER /R/x86_64-pc-linux-gnu-library/4.0 Installing packages into the default location is problematic because any files placed within a user's home directory count against the directories space quota (~2Gb / 4Gb). As R packages can take a considerable amount of space when installed, the best course of action is to change the default library directory. Therefore, R packages should be either stored in a project directory or a purchased space allocation on the cluster that an investor may purchase. The path to an investor's space is given as: /projects/<investor>/shared/ $USER Frequently, the cluster staff will create a symlink into the investor's directory once authorization is given. In the case of Statistics , the investor name is stat , so the directory would be either: /projects/stat/shared/ $USER # or the symlink version: ~/project-stat/ In any case, we recommend creating and registering an r-pkgs directory under the appropriate project space. The registration with R is done using the R_LIBS_USER variable in ~/.Renvion . # Setup the .Renviron file in the home directory touch ~/.Renviron # Append a single variable into the Renvironment file cat << 'EOF' >> ~/.Renviron # Location to R library R_LIBS_USER=~/project-stat/R/%p-library/%v EOF # Construct the path Rscript -e 'dir.create(Sys.getenv(\"R_LIBS_USER\"), recursive = TRUE)' Under this approach, we have move the location of the default package directory to: ~/project-stat/R/%p-library/%v # the expanded version of %p and %v give: ~/project-stat/R/x86_64-pc-linux-gnu-library/x.y Note: After each minor R version upgrade of R x.y, you will need to recreate the package storage directory using: Rscript - e 'dir.create(Sys.getenv(\"R_LIBS_USER\"), recursive = TRUE)' One question that arises: Why not set up a generic personal library directory called ~/Rlibs ? We avoided a generic name for two reasons: New \"major\" releases of R -- and sometime minor versions -- are incompatible with the old packages. Versioning by number allows for graceful downgrades if needed. In the case of the first bullet, its better to start over from a new directory to ensure clean builds. Though, you could opt not to and remember: update.packages ( ask = FALSE , checkBuilt = TRUE ) Install R packages into library \u00b6 Prior to installing an R package, make sure to load the appropriate R version with: module load R / x.y.z where x.y.z is a supported version number, e.g. module load R/3.6.2 will make available R 3.6.2. Once R is loaded, packages can be installed by entering into R or directly from bash. The prior approach will be preferred as it mimics local R installation procedures while the latter approach is useful for one-off packages installations. Enter into an interactive R session from bash by typing: R Then, inside of R , the package installation may be done using: # Install a package install.packages ( 'remotes' , repos = 'https://cloud.r-project.org' ) # Exit out of R and return to bash. q ( save = \"no\" ) Unlike the native R installation route, installing packages under bash uses the Rscript command and requires writing the install command as a string: Rscript -e \"install.packages('remotes', repos = 'https://cloud.r-project.org')\" Be careful when using quotations to specify packages. For each of these commands, we begin and end with \" and, thus, inside the command we use ' to denote strings. With this approach, escaping character strings is avoided. Installing Packages into Development Libraries \u00b6 If you need to use a different library path than what was setup as the default, e.g. ~/project-stat/r-libs , first create the directory and, then, specify a path to it with lib = '' in `install.packages(). mkdir -p ~/project-stat/devel-pkg Rscript -e \"install.packages('remotes', lib = '~/project-stat/devel-pkg', repos = 'https://cloud.r-project.org/')\" Installing Packages from GitHub \u00b6 For packages stored on GitHub, there are two variants for installation depending on the state of the repository. If the repository is public , then the standard install_github(\"user/repo\") may be used. On the other hand, if the repository is private , the package installation call must be accompanied by a GitHub Personal Access Token in the auth_token='' parameter of install_github() . In the prior step, if the ~/.Renviron contains GITHUB_PAT variable, there is no need to specify in the install_github() call as it will automatically be picked up. # Install package from GitHub Rscript -e \"remotes::install_github('coatless/visualize')\" # Install from a private repository on GitHub Rscript -e \"remotes::install_github('stat385/netid', auth_token = 'abc')\" Parallelized package installation \u00b6 By default, all users are placed onto the login nodes. Login nodes are configured for staging and submitting jobs not for installing software. The best practice and absolute fastest way to install software is to use an interactive job . Interactive jobs place the user directly on a compute node with the requested resources, e.g. 10 CPUs or 5GB of memory per CPU. Before installing multiple R packages, we recommend creating an interactive job with: srun --cpus-per-task = 10 --pty bash Once on the interactive node, load the appropriate version of R : module load R / x.y.z # where x.y.z is the version number From here, make sure every package installation call uses the Ncpus = parameter set equal to the number of cores requested for the interactive job. Rscript - e \"install.packages('remotes', repos = 'https://cloud.r-project.org', Ncpus = 10L)\"","title":"Setting up a work environment"},{"location":"cluster-setup/#cluster-setup","text":"Within this chapter, we will cover establishing a workspace on the Campus Cluster. Workspace setup usually requires about 5 different steps. Ensure the cluster can easily be accessed from a local computer. Enable command shortcuts through aliases. Setup a GitHub access token for pulling software in from private repositories (skip if not needed). Create a space on a project drive for where R packages should be installed. Install R packages!","title":"Cluster Setup"},{"location":"cluster-setup/#secure-shell-ssh-setup","text":"For accessing a cluster from command line, Secure Shell (SSH) is preferred. Access to the cluster requires typing out each time: ssh netid@cc-login.campuscluster.illinois.edu # password Connecting in this manner is tedious since it involves repetitively typing out login credentials. There are two tricks that void the necessity to do so. Effectively, we have: Passwordless login Public/Private SSH Keys Alias connection names SSH Config Thus, instead of entering a password, the local computer can submit a private key to be verified by a server. Not only is this more secure, but it avoids the hassle of remembering the password and typing it out while observers watch. Secondly, the connection alias will allow for typing: ssh icc Not bad eh?","title":"Secure Shell (SSH) Setup"},{"location":"cluster-setup/#generating-an-ssh-key","text":"On your local computer, open up Terminal and type: ## Run: ssh-keygen -t rsa -C \"netid@illinois.edu\" ## Respond to: # Enter file in which to save the key (/home/demo/.ssh/id_rsa): # [Press enter] # Enter passphrase (empty for no passphrase): # Write short password","title":"Generating an SSH Key"},{"location":"cluster-setup/#copy-ssh-key-to-server","text":"Next, let's copy the generated key from your local computer onto the cluster. ## Run: ssh-copy-id netid@cc-login.campuscluster.illinois.edu On macOS, prior to using ssh-copy-id , the command will need to be installed. Homebrew provides a formula that will setup the command. Install using: # Install homebrew /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh ) \" # Install the required command binary brew install ssh-copy-id","title":"Copy SSH Key to Server"},{"location":"cluster-setup/#ssh-config-file","text":"Inside of ~/.ssh/config , add the following host configuration. Make sure to replace <netid> value with your personal netid. Host icc HostName cc-login.campuscluster.illinois.edu User netid Note: This assumes a default location is used for the SSH key. If there is a custom SSH key location add IdentityFile ~/.ssh/sshkeyname.key after the User line.","title":"SSH Config File"},{"location":"cluster-setup/#bash-aliases","text":"Bash has the ability to create command aliases through alias . The primary use is to take long commands and create short-cuts to avoid typing them. Alternatively, this allows one to also rename commonly used commands. For example, one could modify the ls command to always list each file and show all hidden files with: alias ls = 'ls -la' ` . We suggest creating a ~/.bash_aliases on the cluster and filling it with: # Learn about own job progress alias jobs_info = 'sacct -u $USER' alias jobs_user = 'squeue -u $USER' alias jobs_active = 'squeue -u $USER --states=RUNNING' alias jobs_waiting = 'squeue -u $USER --states=PENDING' alias jobs_n = 'squeue -u $USER --states=RUNNING | wc -l' # Learn about cluster work alias jobs_stat = 'squeue -o \"%8i %12j %4t %10u %20q %20a %10g %20P %10Q %5D %11l %11L %R\" -p \"stat\"' alias node_config = 'sinfo -o \"%20P %5D %14F %8z %10m %10d %11l %16f %N\"' # Quick action job manipulations alias jobs_hold = 'scontrol hold' alias jobs_release = 'scontrol release' alias jobs_kill_all = 'scancel -u $USER' alias jobs_kill = 'scancel' # Run an interactive job alias si = 'srun --cpus-per-task=5 --pty bash' You may download this directly onto the cluster using: wget https://raw.githubusercontent.com/coatless/hpc/master/docs/config/.bash_aliases To ensure bash aliases are available, we need to add the file to ~/.bashrc : # .bashrc # Source global definitions if [ -f /etc/bashrc ] ; then . /etc/bashrc fi # Source list of alias commands if [ -f ~/.bash_aliases ] ; then . ~/.bash_aliases fi # Auto-load a set of modules if [ -f ~/.init_modules ] ; then . ~/.init_modules fi Note: the load modules component is shown You may download this directly onto the cluster using: rm -rf ~/.bashrc wget https://raw.githubusercontent.com/coatless/hpc/master/docs/config/.bashrc","title":"Bash Aliases"},{"location":"cluster-setup/#optional-github-personal-access-token-pat","text":"We briefly summarize the process for getting and registering a GitHub Personal Access Token in R . The token may be created at: https://github.com/settings/tokens From there, we can add it to the R session with: touch ~/.Renviron cat << EOF >> ~/.Renviron GITHUB_TOKEN=\"your_github_token_here\" GITHUB_PAT=\"your_github_token_here\" EOF Alternatively, within R , the token can be added by typing: file.edit ( \"~/.Renviron\" ) Then, writing in the configuration file: GITHUB_TOKEN = \"your_github_token_here\" GITHUB_PAT = \"your_github_token_here\"","title":"Optional: GitHub Personal Access Token (PAT)"},{"location":"cluster-setup/#default-r-package-storage-location","text":"R 's default library directory where packages are installed into is found within the user's home directory at: # location for R 3.6.z /home/ $USER /R/x86_64-pc-linux-gnu-library/3.6 # location for R 4.0.z /home/ $USER /R/x86_64-pc-linux-gnu-library/4.0 Installing packages into the default location is problematic because any files placed within a user's home directory count against the directories space quota (~2Gb / 4Gb). As R packages can take a considerable amount of space when installed, the best course of action is to change the default library directory. Therefore, R packages should be either stored in a project directory or a purchased space allocation on the cluster that an investor may purchase. The path to an investor's space is given as: /projects/<investor>/shared/ $USER Frequently, the cluster staff will create a symlink into the investor's directory once authorization is given. In the case of Statistics , the investor name is stat , so the directory would be either: /projects/stat/shared/ $USER # or the symlink version: ~/project-stat/ In any case, we recommend creating and registering an r-pkgs directory under the appropriate project space. The registration with R is done using the R_LIBS_USER variable in ~/.Renvion . # Setup the .Renviron file in the home directory touch ~/.Renviron # Append a single variable into the Renvironment file cat << 'EOF' >> ~/.Renviron # Location to R library R_LIBS_USER=~/project-stat/R/%p-library/%v EOF # Construct the path Rscript -e 'dir.create(Sys.getenv(\"R_LIBS_USER\"), recursive = TRUE)' Under this approach, we have move the location of the default package directory to: ~/project-stat/R/%p-library/%v # the expanded version of %p and %v give: ~/project-stat/R/x86_64-pc-linux-gnu-library/x.y Note: After each minor R version upgrade of R x.y, you will need to recreate the package storage directory using: Rscript - e 'dir.create(Sys.getenv(\"R_LIBS_USER\"), recursive = TRUE)' One question that arises: Why not set up a generic personal library directory called ~/Rlibs ? We avoided a generic name for two reasons: New \"major\" releases of R -- and sometime minor versions -- are incompatible with the old packages. Versioning by number allows for graceful downgrades if needed. In the case of the first bullet, its better to start over from a new directory to ensure clean builds. Though, you could opt not to and remember: update.packages ( ask = FALSE , checkBuilt = TRUE )","title":"Default R Package Storage Location"},{"location":"cluster-setup/#install-r-packages-into-library","text":"Prior to installing an R package, make sure to load the appropriate R version with: module load R / x.y.z where x.y.z is a supported version number, e.g. module load R/3.6.2 will make available R 3.6.2. Once R is loaded, packages can be installed by entering into R or directly from bash. The prior approach will be preferred as it mimics local R installation procedures while the latter approach is useful for one-off packages installations. Enter into an interactive R session from bash by typing: R Then, inside of R , the package installation may be done using: # Install a package install.packages ( 'remotes' , repos = 'https://cloud.r-project.org' ) # Exit out of R and return to bash. q ( save = \"no\" ) Unlike the native R installation route, installing packages under bash uses the Rscript command and requires writing the install command as a string: Rscript -e \"install.packages('remotes', repos = 'https://cloud.r-project.org')\" Be careful when using quotations to specify packages. For each of these commands, we begin and end with \" and, thus, inside the command we use ' to denote strings. With this approach, escaping character strings is avoided.","title":"Install R packages into library"},{"location":"cluster-setup/#installing-packages-into-development-libraries","text":"If you need to use a different library path than what was setup as the default, e.g. ~/project-stat/r-libs , first create the directory and, then, specify a path to it with lib = '' in `install.packages(). mkdir -p ~/project-stat/devel-pkg Rscript -e \"install.packages('remotes', lib = '~/project-stat/devel-pkg', repos = 'https://cloud.r-project.org/')\"","title":"Installing Packages into Development Libraries"},{"location":"cluster-setup/#installing-packages-from-github","text":"For packages stored on GitHub, there are two variants for installation depending on the state of the repository. If the repository is public , then the standard install_github(\"user/repo\") may be used. On the other hand, if the repository is private , the package installation call must be accompanied by a GitHub Personal Access Token in the auth_token='' parameter of install_github() . In the prior step, if the ~/.Renviron contains GITHUB_PAT variable, there is no need to specify in the install_github() call as it will automatically be picked up. # Install package from GitHub Rscript -e \"remotes::install_github('coatless/visualize')\" # Install from a private repository on GitHub Rscript -e \"remotes::install_github('stat385/netid', auth_token = 'abc')\"","title":"Installing Packages from GitHub"},{"location":"cluster-setup/#parallelized-package-installation","text":"By default, all users are placed onto the login nodes. Login nodes are configured for staging and submitting jobs not for installing software. The best practice and absolute fastest way to install software is to use an interactive job . Interactive jobs place the user directly on a compute node with the requested resources, e.g. 10 CPUs or 5GB of memory per CPU. Before installing multiple R packages, we recommend creating an interactive job with: srun --cpus-per-task = 10 --pty bash Once on the interactive node, load the appropriate version of R : module load R / x.y.z # where x.y.z is the version number From here, make sure every package installation call uses the Ncpus = parameter set equal to the number of cores requested for the interactive job. Rscript - e \"install.packages('remotes', repos = 'https://cloud.r-project.org', Ncpus = 10L)\"","title":"Parallelized package installation"},{"location":"cluster-software/","text":"Cluster Software \u00b6 Software Modules \u00b6 Unlike a traditional desktop, you must load the different software that you wish to use into the environment via modulefiles . The list of supported software can be found on Software List or by typing: module avail Viewing, Retrieving, and Disabling Module Software \u00b6 The most frequently used module commands are: module list # See active software modules module load <software> # Enable software module unload <software> # Disable software module purge # Removes all active modules Replace <software> with the name of the desired software module from module avail . Latest Version of R \u00b6 As of September 2020 , the latest version of R on ICC is R 4.0.1 . However, we recommend using R 3.6.2 as the 4.0.1 base library has non-standard packages present. R can be accessed by using: # Load software module load R/3.6.2 Note: If the version is not specified during the load, e.g. module load R , then the oldest version of R will be used. Once R is loaded, the Terminal/non-GUI version of R can be started by typing: R To exit an R session on the cluster, type inside R : q(save = \"no\") This will terminate the R session without saving any environment values. Ask for Help \u00b6 ICC's help desk (via help@campuscluster.illinois.edu ) can help install software on ICC. Please send them an e-mail and CC your advisor. Writing a Custom Module \u00b6 It is possible to compile and create your own modules. For details, see the tutorial A Modulefile Approach to Compiling R on a Cluster .","title":"Software"},{"location":"cluster-software/#cluster-software","text":"","title":"Cluster Software"},{"location":"cluster-software/#software-modules","text":"Unlike a traditional desktop, you must load the different software that you wish to use into the environment via modulefiles . The list of supported software can be found on Software List or by typing: module avail","title":"Software Modules"},{"location":"cluster-software/#viewing-retrieving-and-disabling-module-software","text":"The most frequently used module commands are: module list # See active software modules module load <software> # Enable software module unload <software> # Disable software module purge # Removes all active modules Replace <software> with the name of the desired software module from module avail .","title":"Viewing, Retrieving, and Disabling Module Software"},{"location":"cluster-software/#latest-version-of-r","text":"As of September 2020 , the latest version of R on ICC is R 4.0.1 . However, we recommend using R 3.6.2 as the 4.0.1 base library has non-standard packages present. R can be accessed by using: # Load software module load R/3.6.2 Note: If the version is not specified during the load, e.g. module load R , then the oldest version of R will be used. Once R is loaded, the Terminal/non-GUI version of R can be started by typing: R To exit an R session on the cluster, type inside R : q(save = \"no\") This will terminate the R session without saving any environment values.","title":"Latest Version of R"},{"location":"cluster-software/#ask-for-help","text":"ICC's help desk (via help@campuscluster.illinois.edu ) can help install software on ICC. Please send them an e-mail and CC your advisor.","title":"Ask for Help"},{"location":"cluster-software/#writing-a-custom-module","text":"It is possible to compile and create your own modules. For details, see the tutorial A Modulefile Approach to Compiling R on a Cluster .","title":"Writing a Custom Module"},{"location":"cluster-storage/","text":"Storage \u00b6 Storing Data & Code \u00b6 Home Directory ~/ Up to ~2GB (Soft cap) / ~4GB (Hard cap) with nightly backups . Storage is private . Project Spaces /projects/stat/shared/$USER ~21TB of shared space with nightly backups . Storage is shared among stat members. Temporary Networked Storage /scratch ~10TB of space purged after 30 days with no backup . Storage is private . Soft caps : gently warn the user to lower their storage size. Hard caps : prevent the user from adding new files. Backups \u00b6 Backup Info \u00b6 Daily night time backups. 30 days of backups exist. No off-site backups for disaster recovery. Location of Backups \u00b6 Home Directory ~/ /gpfs/iccp/home/.snapshots/home_YYYYMMDD*/ $USER Project Directory /projects/stat/shared/$USER /gpfs/iccp/projects/stat/.snapshots/statistics_YYYYMMDD*","title":"Storage"},{"location":"cluster-storage/#storage","text":"","title":"Storage"},{"location":"cluster-storage/#storing-data-code","text":"Home Directory ~/ Up to ~2GB (Soft cap) / ~4GB (Hard cap) with nightly backups . Storage is private . Project Spaces /projects/stat/shared/$USER ~21TB of shared space with nightly backups . Storage is shared among stat members. Temporary Networked Storage /scratch ~10TB of space purged after 30 days with no backup . Storage is private . Soft caps : gently warn the user to lower their storage size. Hard caps : prevent the user from adding new files.","title":"Storing Data &amp; Code"},{"location":"cluster-storage/#backups","text":"","title":"Backups"},{"location":"cluster-storage/#backup-info","text":"Daily night time backups. 30 days of backups exist. No off-site backups for disaster recovery.","title":"Backup Info"},{"location":"cluster-storage/#location-of-backups","text":"Home Directory ~/ /gpfs/iccp/home/.snapshots/home_YYYYMMDD*/ $USER Project Directory /projects/stat/shared/$USER /gpfs/iccp/projects/stat/.snapshots/statistics_YYYYMMDD*","title":"Location of Backups"},{"location":"errors/","text":"Errors \u00b6 When doing a long-running computation with future.batchtools , you may get the following errors under plan(remote) client_loop: send disconnect: Broken pipe Connection to <host address> closed by remote host.","title":"Errors"},{"location":"errors/#errors","text":"When doing a long-running computation with future.batchtools , you may get the following errors under plan(remote) client_loop: send disconnect: Broken pipe Connection to <host address> closed by remote host.","title":"Errors"},{"location":"mkdocs/","text":"mkdocs steps \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Book Development Guide"},{"location":"mkdocs/#mkdocs-steps","text":"For full documentation visit mkdocs.org .","title":"mkdocs steps"},{"location":"mkdocs/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"mkdocs/#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"notes/","text":"Misc Side notes \u00b6 Finding different Job ID values under a given user is done with: squeue -l -p <partition> | grep PENDING | grep <USER> | awk ' {print $1}' | xargs | sed 's/ /,/g' where <partition is the queue and <user> is the username of who submitted the job.","title":"Misc Side notes"},{"location":"notes/#misc-side-notes","text":"Finding different Job ID values under a given user is done with: squeue -l -p <partition> | grep PENDING | grep <USER> | awk ' {print $1}' | xargs | sed 's/ /,/g' where <partition is the queue and <user> is the username of who submitted the job.","title":"Misc Side notes"},{"location":"build/boost/","text":"Recipes for Boost \u00b6 Contained within are the modulefiles and recipes for building boost.","title":"Recipes for Boost"},{"location":"build/boost/#recipes-for-boost","text":"Contained within are the modulefiles and recipes for building boost.","title":"Recipes for Boost"},{"location":"build/cryptsetup/","text":"Pandoc \u00b6 Contained within are the modulefiles and recipes for building pandoc.","title":"Pandoc"},{"location":"build/cryptsetup/#pandoc","text":"Contained within are the modulefiles and recipes for building pandoc.","title":"Pandoc"},{"location":"build/go/","text":"go \u00b6 Contained within are the modulefiles and recipes for building go.","title":"go"},{"location":"build/go/#go","text":"Contained within are the modulefiles and recipes for building go.","title":"go"},{"location":"build/pandoc/","text":"Pandoc \u00b6 Contained within are the modulefiles and recipes for building pandoc.","title":"Pandoc"},{"location":"build/pandoc/#pandoc","text":"Contained within are the modulefiles and recipes for building pandoc.","title":"Pandoc"},{"location":"build/rstudio-server/","text":"RStudio Server via Singularity \u00b6 Contained within are the modulefiles and scripts for setting up an interactive job on the cluster that launches RStudio Server. On launch, users will see: RStudio Server instance is now available at: http://${HOSTNAME}.campuscluster.illinois.edu:${PORT} >> Warning: Must be on Campus VPN to connect! << For SSH access, please type in terminal: ssh -N -L 8787:${HOSTNAME}:${PORT} ${USER}@cc-login.campuscluster.illinois.edu Then, on your local computer open in a web browser: http://localhost:8787 To login use: Username: ${USER} Password: ${PASSWORD}","title":"RStudio Server via Singularity"},{"location":"build/rstudio-server/#rstudio-server-via-singularity","text":"Contained within are the modulefiles and scripts for setting up an interactive job on the cluster that launches RStudio Server. On launch, users will see: RStudio Server instance is now available at: http://${HOSTNAME}.campuscluster.illinois.edu:${PORT} >> Warning: Must be on Campus VPN to connect! << For SSH access, please type in terminal: ssh -N -L 8787:${HOSTNAME}:${PORT} ${USER}@cc-login.campuscluster.illinois.edu Then, on your local computer open in a web browser: http://localhost:8787 To login use: Username: ${USER} Password: ${PASSWORD}","title":"RStudio Server via Singularity"},{"location":"build/singularity/","text":"Singularity \u00b6 Contained within are the modulefiles and recipes for building singularity.","title":"Singularity"},{"location":"build/singularity/#singularity","text":"Contained within are the modulefiles and recipes for building singularity.","title":"Singularity"},{"location":"pbs/bash-jobs/","text":"Bash \u00b6 Single script \u00b6 sim-script.sh #!/bin/bash ## Ensure that only 2 parameters are passed in ---- if [ $# -ne 2 ] ; then echo \" $0 : usage: ./sim-script param1 param2\" exit 1 fi # Retrieve parameters passed in param1 = $1 param2 = $2 echo \"param1 = ${ param1 } ; param2 = ${ param2 } \" $# : number of arguments passed; $0 : name of the shell or shell script; $1 : the first argument; $n : the nth argument (substitute n with number); $* : all arguments, space issues if unquoted, use \"$@\" ; $@ : all arguments, expands to separate words; or ( Bonus ) $? : Exit status of last script (0 is success). Script with Fixed Parameters \u00b6 #!/bin/bash ## Describe requirements for computing ---- #PBS -q secondary #PBS -l nodes=1:ppn=1 #PBS -l walltime=04:00:00 ## Set variables ---- param1 = 1 param2 = 2 ## Start simulation study ---- cd ~/sim-dir ./sim-script param1 param2 Script with Varying Parameters \u00b6 #!/bin/bash ## Describe requirements for computing ---- #PBS -q secondary #PBS -l nodes=1:ppn=1 #PBS -l walltime=04:00:00 ## Set array variables ---- param1 = ({ 1 , 2 , 3 }) param2 = ({ 4 , 5 , 6 }) ## Start simulation study ---- cd ~/sim-dir for (( i = 0 ; i< ${# param [@] } ; ++i )) ; do ./sim-script ${ param1 [i] } ${ param2 [i] } done Parallelized Script with Varying Parameters \u00b6 #!/bin/bash ## Describe requirements for computing ---- #PBS -q secondary #PBS -l nodes=1:ppn=3 #PBS -l walltime=04:00:00 ## Set array variables ---- param1 =({ 1 ,2,3 }) param2 =({ 4 ,5,6 }) ## Start simulation study ---- cd ~/sim-dir ## Run simulations in parallel ---- for (( i = 0 ; i< ${# param [@] } ; ++i )) ; do ./sim-script ${ param1 [i] } ${ param2 [i] } & # Ampersand runs script in background process_id [ i ]= $! # Store the Process ID done ## Wait for all processes to complete ---- for (( i = 0 ; i< ${# param [@] } ; ++i )) ; do echo \"Awaiting results for ${ process_id [i] } .\" wait ${ process_id [i] } done","title":"Common Jobs in Bash"},{"location":"pbs/bash-jobs/#bash","text":"","title":"Bash"},{"location":"pbs/bash-jobs/#single-script","text":"sim-script.sh #!/bin/bash ## Ensure that only 2 parameters are passed in ---- if [ $# -ne 2 ] ; then echo \" $0 : usage: ./sim-script param1 param2\" exit 1 fi # Retrieve parameters passed in param1 = $1 param2 = $2 echo \"param1 = ${ param1 } ; param2 = ${ param2 } \" $# : number of arguments passed; $0 : name of the shell or shell script; $1 : the first argument; $n : the nth argument (substitute n with number); $* : all arguments, space issues if unquoted, use \"$@\" ; $@ : all arguments, expands to separate words; or ( Bonus ) $? : Exit status of last script (0 is success).","title":"Single script"},{"location":"pbs/bash-jobs/#script-with-fixed-parameters","text":"#!/bin/bash ## Describe requirements for computing ---- #PBS -q secondary #PBS -l nodes=1:ppn=1 #PBS -l walltime=04:00:00 ## Set variables ---- param1 = 1 param2 = 2 ## Start simulation study ---- cd ~/sim-dir ./sim-script param1 param2","title":"Script with Fixed Parameters"},{"location":"pbs/bash-jobs/#script-with-varying-parameters","text":"#!/bin/bash ## Describe requirements for computing ---- #PBS -q secondary #PBS -l nodes=1:ppn=1 #PBS -l walltime=04:00:00 ## Set array variables ---- param1 = ({ 1 , 2 , 3 }) param2 = ({ 4 , 5 , 6 }) ## Start simulation study ---- cd ~/sim-dir for (( i = 0 ; i< ${# param [@] } ; ++i )) ; do ./sim-script ${ param1 [i] } ${ param2 [i] } done","title":"Script with Varying Parameters"},{"location":"pbs/bash-jobs/#parallelized-script-with-varying-parameters","text":"#!/bin/bash ## Describe requirements for computing ---- #PBS -q secondary #PBS -l nodes=1:ppn=3 #PBS -l walltime=04:00:00 ## Set array variables ---- param1 =({ 1 ,2,3 }) param2 =({ 4 ,5,6 }) ## Start simulation study ---- cd ~/sim-dir ## Run simulations in parallel ---- for (( i = 0 ; i< ${# param [@] } ; ++i )) ; do ./sim-script ${ param1 [i] } ${ param2 [i] } & # Ampersand runs script in background process_id [ i ]= $! # Store the Process ID done ## Wait for all processes to complete ---- for (( i = 0 ; i< ${# param [@] } ; ++i )) ; do echo \"Awaiting results for ${ process_id [i] } .\" wait ${ process_id [i] } done","title":"Parallelized Script with Varying Parameters"},{"location":"pbs/r-jobs/","text":"R \u00b6 Sample simulation script \u00b6 # Expect command line args at the end. args = commandArgs ( trailingOnly = TRUE ) # Skip args[1] to prevent getting --args # Extract and cast as numeric from character rnorm ( n = as.numeric ( args [ 2 ]), mean = as.numeric ( args [ 3 ])) Script with Fixed Parameters \u00b6 #!/bin/bash ## Describe requirements for computing ---- ## Set the maximum amount of runtime to 4 Hours #PBS -l walltime=04:00:00 ## Request one node with `nodes` and one core with `ppn` #PBS -l nodes=1:ppn=1 #PBS -l naccesspolicy=shared ## Name the job #PBS -N jobname ## Queue in the secondary queue #PBS -q secondary ## Merge standard output into error output #PBS -j oe ## Setup computing environment for job ---- ## Create a directory for the data output based ## on PBS_JOBID mkdir ${ PBS_O_WORKDIR } / ${ PBS_JOBID } ## Switch directory into job ID (puts all output here) cd ${ PBS_O_WORKDIR } / ${ PBS_JOBID } # Load R ## Run simulation ---- ## Load latest version of R loaded module load R/3.6.2 ## Run R script in batch mode without file output Rscript $HOME /sim_runner.R --args 5 10","title":"Common Jobs in R"},{"location":"pbs/r-jobs/#r","text":"","title":"R"},{"location":"pbs/r-jobs/#sample-simulation-script","text":"# Expect command line args at the end. args = commandArgs ( trailingOnly = TRUE ) # Skip args[1] to prevent getting --args # Extract and cast as numeric from character rnorm ( n = as.numeric ( args [ 2 ]), mean = as.numeric ( args [ 3 ]))","title":"Sample simulation script"},{"location":"pbs/r-jobs/#script-with-fixed-parameters","text":"#!/bin/bash ## Describe requirements for computing ---- ## Set the maximum amount of runtime to 4 Hours #PBS -l walltime=04:00:00 ## Request one node with `nodes` and one core with `ppn` #PBS -l nodes=1:ppn=1 #PBS -l naccesspolicy=shared ## Name the job #PBS -N jobname ## Queue in the secondary queue #PBS -q secondary ## Merge standard output into error output #PBS -j oe ## Setup computing environment for job ---- ## Create a directory for the data output based ## on PBS_JOBID mkdir ${ PBS_O_WORKDIR } / ${ PBS_JOBID } ## Switch directory into job ID (puts all output here) cd ${ PBS_O_WORKDIR } / ${ PBS_JOBID } # Load R ## Run simulation ---- ## Load latest version of R loaded module load R/3.6.2 ## Run R script in batch mode without file output Rscript $HOME /sim_runner.R --args 5 10","title":"Script with Fixed Parameters"},{"location":"slurm/array-jobs-r/","text":"Array Submission of Multiple Independent R Jobs \u00b6 Consider the need to obtain random numbers across varying sample sizes and means. \\[N = \\begin{cases} 250 \\\\ 500 \\\\ 750 \\end{cases}, \\mu = \\begin{cases} 0 \\\\ 1.5 \\end{cases}\\] Sample Job Script \u00b6 sim_job.R # Expect command line args at the end. args = commandArgs ( trailingOnly = TRUE ) # Skip args[1] to prevent getting --args # Extract and cast as numeric from character rnorm ( n = as.numeric ( args [ 2 ]), mean = as.numeric ( args [ 3 ])) Download a copy onto the cluster with: wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/sim_job.R chmod +x sim_job.R Sample Parameter Inputs \u00b6 inputs.txt 250 0 500 0 750 0 250 1 .5 500 1 .5 750 1 .5 Download a copy onto the cluster with: # Download a pre-made inputs.txt onto the cluster wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/inputs.txt Note: Parameters are best generated using expand.grid() . N_vals = c ( 250 , 500 , 750 ) mu_vals = c ( 0 , 1.5 ) sim_frame = expand.grid ( N = N_vals , mu = mu_vals ) sim_frame # 250 0.0 # 500 0.0 # 750 0.0 # 250 1.5 # 500 1.5 # 750 1.5 Write the simulation parameter configuration to inputs.txt with: write.table ( sim_frame , file = \"inputs.txt\" , col.names = FALSE , row.names = FALSE ) Array Job Launch \u00b6 sim_array_launch.slurm #!/bin/bash ## Describe requirements for computing ---- ## Name the job to ID it in squeue -u $USER #SBATCH --job-name=myjobarray ## Send email on any change in job status (NONE, BEGIN, END, FAIL, ALL) ## Note: To be notified on each task on the array use: ALL,ARRAY_TASKS #SBATCH --mail-type=ALL ## Email address of where the notification should be sent. #SBATCH --mail-user=netid@illinois.edu ## Amount of time the job should run ## Note: specified in hour:min:sec, e.g. 01:30:00 is a 1 hour and 30 min job. #SBATCH --time=00:10:00 ## Request a single node #SBATCH --ntasks=1 ## Specify number of CPU cores for parallel jobs ## Note: Leave at 1 if not running in parallel. #SBATCH --cpus-per-task=1 ## Request a maximum amount of RAM per CPU core ## Note: For memory intensive work, set to a higher amount of ram. #SBATCH --mem-per-cpu=5gb ## Standard output and error log #SBATCH --output=myjobarray_%A-%a.out # Array range #SBATCH --array=1-6 ## Setup computing environment for job ---- ## Create a directory for the data output based on the SLURM_ARRAY_JOB_ID mkdir -p ${ SLURM_SUBMIT_DIR } / ${ SLURM_ARRAY_JOB_ID } ## Switch directory into job ID (puts all output here) cd ${ SLURM_SUBMIT_DIR } / ${ SLURM_ARRAY_JOB_ID } ## Run simulation ---- ## Load a pre-set version of R module load R/3.6.2 ## Grab the appropriate line from the input file. ## Put that in a shell variable named \"PARAMS\" export PARAMS = ` cat ${ HOME } /inputs.txt | sed -n ${ SLURM_ARRAY_TASK_ID } p ` ## Run R script in batch mode without file output Rscript $HOME /sim_job.R --args $PARAMS Download a copy and run it on the cluster with: # Download script file wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/sim_array_launch.slurm # Queue the job on the Cluster sbatch sim_array_launch.slurm Note: %A will be replaced by the value of the SLURM_ARRAY_JOB_ID environment variable and %a will be replaced by the value of SLURM_ARRAY_TASK_ID environment variable. For example, SLURM_ARRAY_JOB_ID corresponds to the number assigned to the job in the queue and SLURM_ARRAY_TASK_ID relates to a value in the job array. In the case of this example, the SLURM_ARRAY_TASK_ID would take on values from 1 to 6.","title":"Array Jobs with R"},{"location":"slurm/array-jobs-r/#array-submission-of-multiple-independent-r-jobs","text":"Consider the need to obtain random numbers across varying sample sizes and means. \\[N = \\begin{cases} 250 \\\\ 500 \\\\ 750 \\end{cases}, \\mu = \\begin{cases} 0 \\\\ 1.5 \\end{cases}\\]","title":"Array Submission of Multiple Independent R Jobs"},{"location":"slurm/array-jobs-r/#sample-job-script","text":"sim_job.R # Expect command line args at the end. args = commandArgs ( trailingOnly = TRUE ) # Skip args[1] to prevent getting --args # Extract and cast as numeric from character rnorm ( n = as.numeric ( args [ 2 ]), mean = as.numeric ( args [ 3 ])) Download a copy onto the cluster with: wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/sim_job.R chmod +x sim_job.R","title":"Sample Job Script"},{"location":"slurm/array-jobs-r/#sample-parameter-inputs","text":"inputs.txt 250 0 500 0 750 0 250 1 .5 500 1 .5 750 1 .5 Download a copy onto the cluster with: # Download a pre-made inputs.txt onto the cluster wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/inputs.txt Note: Parameters are best generated using expand.grid() . N_vals = c ( 250 , 500 , 750 ) mu_vals = c ( 0 , 1.5 ) sim_frame = expand.grid ( N = N_vals , mu = mu_vals ) sim_frame # 250 0.0 # 500 0.0 # 750 0.0 # 250 1.5 # 500 1.5 # 750 1.5 Write the simulation parameter configuration to inputs.txt with: write.table ( sim_frame , file = \"inputs.txt\" , col.names = FALSE , row.names = FALSE )","title":"Sample Parameter Inputs"},{"location":"slurm/array-jobs-r/#array-job-launch","text":"sim_array_launch.slurm #!/bin/bash ## Describe requirements for computing ---- ## Name the job to ID it in squeue -u $USER #SBATCH --job-name=myjobarray ## Send email on any change in job status (NONE, BEGIN, END, FAIL, ALL) ## Note: To be notified on each task on the array use: ALL,ARRAY_TASKS #SBATCH --mail-type=ALL ## Email address of where the notification should be sent. #SBATCH --mail-user=netid@illinois.edu ## Amount of time the job should run ## Note: specified in hour:min:sec, e.g. 01:30:00 is a 1 hour and 30 min job. #SBATCH --time=00:10:00 ## Request a single node #SBATCH --ntasks=1 ## Specify number of CPU cores for parallel jobs ## Note: Leave at 1 if not running in parallel. #SBATCH --cpus-per-task=1 ## Request a maximum amount of RAM per CPU core ## Note: For memory intensive work, set to a higher amount of ram. #SBATCH --mem-per-cpu=5gb ## Standard output and error log #SBATCH --output=myjobarray_%A-%a.out # Array range #SBATCH --array=1-6 ## Setup computing environment for job ---- ## Create a directory for the data output based on the SLURM_ARRAY_JOB_ID mkdir -p ${ SLURM_SUBMIT_DIR } / ${ SLURM_ARRAY_JOB_ID } ## Switch directory into job ID (puts all output here) cd ${ SLURM_SUBMIT_DIR } / ${ SLURM_ARRAY_JOB_ID } ## Run simulation ---- ## Load a pre-set version of R module load R/3.6.2 ## Grab the appropriate line from the input file. ## Put that in a shell variable named \"PARAMS\" export PARAMS = ` cat ${ HOME } /inputs.txt | sed -n ${ SLURM_ARRAY_TASK_ID } p ` ## Run R script in batch mode without file output Rscript $HOME /sim_job.R --args $PARAMS Download a copy and run it on the cluster with: # Download script file wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/sim_array_launch.slurm # Queue the job on the Cluster sbatch sim_array_launch.slurm Note: %A will be replaced by the value of the SLURM_ARRAY_JOB_ID environment variable and %a will be replaced by the value of SLURM_ARRAY_TASK_ID environment variable. For example, SLURM_ARRAY_JOB_ID corresponds to the number assigned to the job in the queue and SLURM_ARRAY_TASK_ID relates to a value in the job array. In the case of this example, the SLURM_ARRAY_TASK_ID would take on values from 1 to 6.","title":"Array Job Launch"},{"location":"slurm/bash-jobs/","text":"Bash \u00b6 Single script \u00b6 sim-script.sh #!/bin/bash ## Ensure that only 2 parameters are passed in ---- if [ $# -ne 2 ] ; then echo \" $0 : usage: ./sim-script param1 param2\" exit 1 fi # Retrieve parameters passed in param1 = $1 param2 = $2 echo \"param1 = ${ param1 } ; param2 = ${ param2 } \" $# : number of arguments passed; $0 : name of the shell or shell script; $1 : the first argument; $n : the nth argument (substitute n with number); $* : all arguments, space issues if unquoted, use \"$@\" ; $@ : all arguments, expands to separate words; or ( Bonus ) $? : Exit status of last script (0 is success). Script with Fixed Parameters \u00b6 #!/bin/bash ## Describe requirements for computing ---- #PBS -q secondary #PBS -l nodes=1:ppn=1 #PBS -l walltime=04:00:00 ## Set variables ---- param1 = 1 param2 = 2 ## Start simulation study ---- cd ~/sim-dir ./sim-script param1 param2 Script with Varying Parameters \u00b6 #!/bin/bash ## Describe requirements for computing ---- #PBS -q secondary #PBS -l nodes=1:ppn=1 #PBS -l walltime=04:00:00 ## Set array variables ---- param1 = ({ 1 , 2 , 3 }) param2 = ({ 4 , 5 , 6 }) ## Start simulation study ---- cd ~/sim-dir for (( i = 0 ; i< ${# param [@] } ; ++i )) ; do ./sim-script ${ param1 [i] } ${ param2 [i] } done Parallelized Script with Varying Parameters \u00b6 #!/bin/bash ## Describe requirements for computing ---- #PBS -q secondary #PBS -l nodes=1:ppn=3 #PBS -l walltime=04:00:00 ## Set array variables ---- param1 =({ 1 ,2,3 }) param2 =({ 4 ,5,6 }) ## Start simulation study ---- cd ~/sim-dir ## Run simulations in parallel ---- for (( i = 0 ; i< ${# param [@] } ; ++i )) ; do ./sim-script ${ param1 [i] } ${ param2 [i] } & # Ampersand runs script in background process_id [ i ]= $! # Store the Process ID done ## Wait for all processes to complete ---- for (( i = 0 ; i< ${# param [@] } ; ++i )) ; do echo \"Awaiting results for ${ process_id [i] } .\" wait ${ process_id [i] } done","title":"Common Jobs in Bash"},{"location":"slurm/bash-jobs/#bash","text":"","title":"Bash"},{"location":"slurm/bash-jobs/#single-script","text":"sim-script.sh #!/bin/bash ## Ensure that only 2 parameters are passed in ---- if [ $# -ne 2 ] ; then echo \" $0 : usage: ./sim-script param1 param2\" exit 1 fi # Retrieve parameters passed in param1 = $1 param2 = $2 echo \"param1 = ${ param1 } ; param2 = ${ param2 } \" $# : number of arguments passed; $0 : name of the shell or shell script; $1 : the first argument; $n : the nth argument (substitute n with number); $* : all arguments, space issues if unquoted, use \"$@\" ; $@ : all arguments, expands to separate words; or ( Bonus ) $? : Exit status of last script (0 is success).","title":"Single script"},{"location":"slurm/bash-jobs/#script-with-fixed-parameters","text":"#!/bin/bash ## Describe requirements for computing ---- #PBS -q secondary #PBS -l nodes=1:ppn=1 #PBS -l walltime=04:00:00 ## Set variables ---- param1 = 1 param2 = 2 ## Start simulation study ---- cd ~/sim-dir ./sim-script param1 param2","title":"Script with Fixed Parameters"},{"location":"slurm/bash-jobs/#script-with-varying-parameters","text":"#!/bin/bash ## Describe requirements for computing ---- #PBS -q secondary #PBS -l nodes=1:ppn=1 #PBS -l walltime=04:00:00 ## Set array variables ---- param1 = ({ 1 , 2 , 3 }) param2 = ({ 4 , 5 , 6 }) ## Start simulation study ---- cd ~/sim-dir for (( i = 0 ; i< ${# param [@] } ; ++i )) ; do ./sim-script ${ param1 [i] } ${ param2 [i] } done","title":"Script with Varying Parameters"},{"location":"slurm/bash-jobs/#parallelized-script-with-varying-parameters","text":"#!/bin/bash ## Describe requirements for computing ---- #PBS -q secondary #PBS -l nodes=1:ppn=3 #PBS -l walltime=04:00:00 ## Set array variables ---- param1 =({ 1 ,2,3 }) param2 =({ 4 ,5,6 }) ## Start simulation study ---- cd ~/sim-dir ## Run simulations in parallel ---- for (( i = 0 ; i< ${# param [@] } ; ++i )) ; do ./sim-script ${ param1 [i] } ${ param2 [i] } & # Ampersand runs script in background process_id [ i ]= $! # Store the Process ID done ## Wait for all processes to complete ---- for (( i = 0 ; i< ${# param [@] } ; ++i )) ; do echo \"Awaiting results for ${ process_id [i] } .\" wait ${ process_id [i] } done","title":"Parallelized Script with Varying Parameters"},{"location":"slurm/custom-array-jobs-creation-r/","text":"Submit Multiple Independent Jobs \u00b6 Note: This technique was developed to submit jobs to the cluster due to the job array being disabled long ago. With the switch to Slurm, the job array is now available. Consider the need to obtain random numbers across varying sample sizes and means. \\[N = \\begin{cases} 250 \\\\ 500 \\\\ 750 \\end{cases}, \\mu = \\begin{cases} 0 \\\\ 1.5 \\end{cases}\\] Sample Job script \u00b6 sim_job.R # Expect command line args at the end. args = commandArgs ( trailingOnly = TRUE ) # Skip args[1] to prevent getting --args # Extract and cast as numeric from character rnorm ( n = as.numeric ( args [ 2 ]), mean = as.numeric ( args [ 3 ])) Download a copy onto the cluster with: wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/sim_job.R chmod +x sim_job.R Sample Parameter Inputs \u00b6 inputs.txt 250 0 500 0 750 0 250 1 .5 500 1 .5 750 1 .5 Download a copy onto the cluster with: wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/inputs.txt Note: Parameters are best generated using expand.grid() . N_vals = c ( 250 , 500 , 750 ) mu_vals = c ( 0 , 1.5 ) sim_frame = expand.grid ( N = N_vals , mu = mu_vals ) sim_frame # 250 0.0 # 500 0.0 # 750 0.0 # 250 1.5 # 500 1.5 # 750 1.5 Write the simulation parameter configuration to inputs.txt with: write.table ( sim_frame , file = \"inputs.txt\" , col.names = FALSE , row.names = FALSE ) Faux Job Array Script \u00b6 #!/bin/bash ######################################################## # job_builder.sh # Job Arrays without the Resource Manager # Version 2.0.0 ######################################################## # James Joseph Balamuta # balamut2@illinois.edu ######################################################## # ## Example # # # Allow the builder script to work on the file system # chmod +x job_builder.sh # # # Run the job builder # ./job_builder.sh ######################################################## ### Builds the job index # Create a sequential range array_values = ` seq 1 3 ` # Add individual job values # Note: Have a \"space\" before first element!!!! array_values += \" 4 5\" # Warning: This does _not_ pad numbers meaning job IDs created will _not_ be # sorted appropriately on the file system ### Generate a Slurm file for each Job ID # Modify the contents of the Slurm file to be relevant to your simulation ## Set the duration the job should run in hours:minutes:seconds form. ## Note: Submissions to secondary queue are limited to 4 Hours WALLTIME = 04 :00:00 SIM_NAME = sample_job SIM_OUTPUT = sample_job_output SIM_QUEUE = secondary SIM_RAM = \"2gb\" INPUT_CONFIG_FILE = \\$ HOME/input_params R_VERSION = 3 .6.2 R_SCRIPT_FILE = \\$ HOME/sim_job.R SLURM_FILE_NAME = sample_job_single ### -------- Do not modify below here -------- #### for i in $array_values do cat > ${ SLURM_FILE_NAME }${ i } .slurm << EOF #!/bin/bash # ## Set the maximum amount of runtime #SBATCH --time=${WALLTIME} ## ## Request one node with and one core (multiple under slurm is done with X*Y) #SBATCH --ntasks=1 ## Name the job and queue it in xthe secondary queue #SBATCH --job-name=\"${SIM_NAME}${i}\" #SBATCH --partition=\"${SIM_QUEUE}\" ## Declare an output log for all jobs to use: #SBATCH --output=\"${SIM_NAME}.log\" #SBATCH --mem-per-cpu=\"${SIM_RAM}\" mkdir \\$SLURM_SUBMIT_DIR/$SIM_OUTPUT cd \\$SLURM_SUBMIT_DIR/$SIM_OUTPUT module load R/$R_VERSION export PARAMS=\\`cat $INPUT_CONFIG_FILE | sed -n ${i}p\\` R -q -f $R_SCRIPT_FILE --args \\$PARAMS > data${i} exit 0; EOF done # Launch the job and then remove the temporarily created qsub file. for i in $array_values do # This submits the single job to the resource manager sbatch ${ SLURM_FILE_NAME }${ i } .slurm # This removes the job file as Slurm reads the script at submission time rm -rf ${ SLURM_FILE_NAME }${ i } .slurm done Download a copy and run on the cluster with: # Download a copy wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/job_builder.sh # Enable the script to run. chmod +x job_builder.sh # Submit jobs to the queue ./job_builder.sh","title":"Custom Array Job Creation with R"},{"location":"slurm/custom-array-jobs-creation-r/#submit-multiple-independent-jobs","text":"Note: This technique was developed to submit jobs to the cluster due to the job array being disabled long ago. With the switch to Slurm, the job array is now available. Consider the need to obtain random numbers across varying sample sizes and means. \\[N = \\begin{cases} 250 \\\\ 500 \\\\ 750 \\end{cases}, \\mu = \\begin{cases} 0 \\\\ 1.5 \\end{cases}\\]","title":"Submit Multiple Independent Jobs"},{"location":"slurm/custom-array-jobs-creation-r/#sample-job-script","text":"sim_job.R # Expect command line args at the end. args = commandArgs ( trailingOnly = TRUE ) # Skip args[1] to prevent getting --args # Extract and cast as numeric from character rnorm ( n = as.numeric ( args [ 2 ]), mean = as.numeric ( args [ 3 ])) Download a copy onto the cluster with: wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/sim_job.R chmod +x sim_job.R","title":"Sample Job script"},{"location":"slurm/custom-array-jobs-creation-r/#sample-parameter-inputs","text":"inputs.txt 250 0 500 0 750 0 250 1 .5 500 1 .5 750 1 .5 Download a copy onto the cluster with: wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/inputs.txt Note: Parameters are best generated using expand.grid() . N_vals = c ( 250 , 500 , 750 ) mu_vals = c ( 0 , 1.5 ) sim_frame = expand.grid ( N = N_vals , mu = mu_vals ) sim_frame # 250 0.0 # 500 0.0 # 750 0.0 # 250 1.5 # 500 1.5 # 750 1.5 Write the simulation parameter configuration to inputs.txt with: write.table ( sim_frame , file = \"inputs.txt\" , col.names = FALSE , row.names = FALSE )","title":"Sample Parameter Inputs"},{"location":"slurm/custom-array-jobs-creation-r/#faux-job-array-script","text":"#!/bin/bash ######################################################## # job_builder.sh # Job Arrays without the Resource Manager # Version 2.0.0 ######################################################## # James Joseph Balamuta # balamut2@illinois.edu ######################################################## # ## Example # # # Allow the builder script to work on the file system # chmod +x job_builder.sh # # # Run the job builder # ./job_builder.sh ######################################################## ### Builds the job index # Create a sequential range array_values = ` seq 1 3 ` # Add individual job values # Note: Have a \"space\" before first element!!!! array_values += \" 4 5\" # Warning: This does _not_ pad numbers meaning job IDs created will _not_ be # sorted appropriately on the file system ### Generate a Slurm file for each Job ID # Modify the contents of the Slurm file to be relevant to your simulation ## Set the duration the job should run in hours:minutes:seconds form. ## Note: Submissions to secondary queue are limited to 4 Hours WALLTIME = 04 :00:00 SIM_NAME = sample_job SIM_OUTPUT = sample_job_output SIM_QUEUE = secondary SIM_RAM = \"2gb\" INPUT_CONFIG_FILE = \\$ HOME/input_params R_VERSION = 3 .6.2 R_SCRIPT_FILE = \\$ HOME/sim_job.R SLURM_FILE_NAME = sample_job_single ### -------- Do not modify below here -------- #### for i in $array_values do cat > ${ SLURM_FILE_NAME }${ i } .slurm << EOF #!/bin/bash # ## Set the maximum amount of runtime #SBATCH --time=${WALLTIME} ## ## Request one node with and one core (multiple under slurm is done with X*Y) #SBATCH --ntasks=1 ## Name the job and queue it in xthe secondary queue #SBATCH --job-name=\"${SIM_NAME}${i}\" #SBATCH --partition=\"${SIM_QUEUE}\" ## Declare an output log for all jobs to use: #SBATCH --output=\"${SIM_NAME}.log\" #SBATCH --mem-per-cpu=\"${SIM_RAM}\" mkdir \\$SLURM_SUBMIT_DIR/$SIM_OUTPUT cd \\$SLURM_SUBMIT_DIR/$SIM_OUTPUT module load R/$R_VERSION export PARAMS=\\`cat $INPUT_CONFIG_FILE | sed -n ${i}p\\` R -q -f $R_SCRIPT_FILE --args \\$PARAMS > data${i} exit 0; EOF done # Launch the job and then remove the temporarily created qsub file. for i in $array_values do # This submits the single job to the resource manager sbatch ${ SLURM_FILE_NAME }${ i } .slurm # This removes the job file as Slurm reads the script at submission time rm -rf ${ SLURM_FILE_NAME }${ i } .slurm done Download a copy and run on the cluster with: # Download a copy wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/job_builder.sh # Enable the script to run. chmod +x job_builder.sh # Submit jobs to the queue ./job_builder.sh","title":"Faux Job Array Script"},{"location":"slurm/single-job-r/","text":"Single Independent R Job \u00b6 Consider the need to obtain random numbers across varying sample sizes and means. \\[N = \\begin{cases} 250 \\\\ 500 \\\\ 750 \\end{cases}, \\mu = \\begin{cases} 0 \\\\ 1.5 \\end{cases}\\] Sample Job Script \u00b6 sim_job.R # Expect command line args at the end. args = commandArgs ( trailingOnly = TRUE ) # Skip args[1] to prevent getting --args # Extract and cast as numeric from character rnorm ( n = as.numeric ( args [ 2 ]), mean = as.numeric ( args [ 3 ])) Download a copy and run it on the cluster with: # Download a copy of the script onto the cluster wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/sim_job.R # Execute the script with parameter values Rscript $HOME /sim_job.R --args 5 10 # [1] 9.006482 11.288477 11.109700 12.280027 9.500943 Sample Slurm Submission File \u00b6 sim_single_launch.slurm #!/bin/bash ## Describe requirements for computing ---- ## Name the job to ID it in squeue -u $USER #SBATCH --job-name=myjobarray ## Send email on any change in job status (NONE, BEGIN, END, FAIL, ALL) ## Note: To be notified on each task on the array use: ALL,ARRAY_TASKS #SBATCH --mail-type=ALL ## Email address of where the notification should be sent. #SBATCH --mail-user=netid@illinois.edu ## Amount of time the job should run ## Note: specified in hour:min:sec, e.g. 01:30:00 is a 1 hour and 30 min job. #SBATCH --time=00:10:00 ## Request a single node #SBATCH --ntasks=1 ## Specify number of CPU cores for parallel jobs ## Note: Leave at 1 if not running in parallel. #SBATCH --cpus-per-task=1 ## Request a maximum amount of RAM per CPU core ## Note: For memory intensive work, set to a higher amount of ram. #SBATCH --mem-per-cpu=5gb ## Setup computing environment for job ---- ## Create a directory for the data output based SLURM_JOBID assigned to job mkdir ${ SLURM_SUBMIT_DIR } / ${ SLURM_JOBID } ## Switch directory into job ID (puts all output here) cd ${ SLURM_SUBMIT_DIR } / ${ SLURM_JOBID } ## Run simulation ---- ## Load a pre-specified version of R module load R/3.6.2 ## Run R script in batch mode without file output Rscript $HOME /sim_job.R --args 5 10 # Download a copy of the script onto the cluster wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/sim_single_launch.slurm # Queue the job on the Cluster sbatch sim_single_launch.slurm","title":"Single Job using R"},{"location":"slurm/single-job-r/#single-independent-r-job","text":"Consider the need to obtain random numbers across varying sample sizes and means. \\[N = \\begin{cases} 250 \\\\ 500 \\\\ 750 \\end{cases}, \\mu = \\begin{cases} 0 \\\\ 1.5 \\end{cases}\\]","title":"Single Independent R Job"},{"location":"slurm/single-job-r/#sample-job-script","text":"sim_job.R # Expect command line args at the end. args = commandArgs ( trailingOnly = TRUE ) # Skip args[1] to prevent getting --args # Extract and cast as numeric from character rnorm ( n = as.numeric ( args [ 2 ]), mean = as.numeric ( args [ 3 ])) Download a copy and run it on the cluster with: # Download a copy of the script onto the cluster wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/sim_job.R # Execute the script with parameter values Rscript $HOME /sim_job.R --args 5 10 # [1] 9.006482 11.288477 11.109700 12.280027 9.500943","title":"Sample Job Script"},{"location":"slurm/single-job-r/#sample-slurm-submission-file","text":"sim_single_launch.slurm #!/bin/bash ## Describe requirements for computing ---- ## Name the job to ID it in squeue -u $USER #SBATCH --job-name=myjobarray ## Send email on any change in job status (NONE, BEGIN, END, FAIL, ALL) ## Note: To be notified on each task on the array use: ALL,ARRAY_TASKS #SBATCH --mail-type=ALL ## Email address of where the notification should be sent. #SBATCH --mail-user=netid@illinois.edu ## Amount of time the job should run ## Note: specified in hour:min:sec, e.g. 01:30:00 is a 1 hour and 30 min job. #SBATCH --time=00:10:00 ## Request a single node #SBATCH --ntasks=1 ## Specify number of CPU cores for parallel jobs ## Note: Leave at 1 if not running in parallel. #SBATCH --cpus-per-task=1 ## Request a maximum amount of RAM per CPU core ## Note: For memory intensive work, set to a higher amount of ram. #SBATCH --mem-per-cpu=5gb ## Setup computing environment for job ---- ## Create a directory for the data output based SLURM_JOBID assigned to job mkdir ${ SLURM_SUBMIT_DIR } / ${ SLURM_JOBID } ## Switch directory into job ID (puts all output here) cd ${ SLURM_SUBMIT_DIR } / ${ SLURM_JOBID } ## Run simulation ---- ## Load a pre-specified version of R module load R/3.6.2 ## Run R script in batch mode without file output Rscript $HOME /sim_job.R --args 5 10 # Download a copy of the script onto the cluster wget https://raw.githubusercontent.com/coatless/hpc/master/docs/slurm/scripts/sim_single_launch.slurm # Queue the job on the Cluster sbatch sim_single_launch.slurm","title":"Sample Slurm Submission File"}]}